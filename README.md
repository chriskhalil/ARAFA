# ARAFA

Automatic fact checking poses a significant challenge in Arabic natural language processing due to the scarcity of datasets and resources. In this paper, we introduce \dataset, a new large-scale dataset for fact checking in Modern Standard Arabic, constructed through an automated framework leveraging large language models (LLMs). The dataset was constructed through a three-step pipeline: (1) claim generation from Arabic Wikipedia pages with supporting textual evidence, (2) claim mutation to generate challenging counterfactual claims with refuting evidence, and (3) an automatic validation step to validate that the generated claims are either supported or refuted by their accompanying evidence, or if the evidence does not provide enough information to judge the validity of the claims. The resulting dataset comprises 181,976 claim-evidence pairs labeled as \textit{supported}, \textit{refuted}, or \textit{not enough information}. Human evaluation carried out on a test sample from the dataset demonstrated strong inter-annotator agreement ($\kappa = 0.89$) using Cohenâ€™s Kappa for supported claims and ($\kappa = 0.94$) for refuted claims. Automatic validation based on the human-evaluated sample achieved 86\% accuracy for supported claims and 88\% for refuted ones. In addition to \dataset being the first large-scale automated dataset for Arabic fact checking, our framework presents a scalable approach for developing similar resources for other low-resource languages.
